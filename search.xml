<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CTFer配套题目解题记录</title>
    <url>/2021/05/13/CTF/CTFer%E9%85%8D%E5%A5%97%E9%A2%98%E7%9B%AE%E8%A7%A3%E9%A2%98%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p><object data="./answers.pdf" type="application/pdf" width="100%" height="900px">This browser does not support PDFs. Please download the PDF to view it: <a href="/index.pdf">Download PDF</a><br></object></p>
<p>文中latex源码、提到的题目、源码、writeup均位于<a href="https://github.com/shijy16/learn-ctf%E3%80%82">https://github.com/shijy16/learn-ctf。</a></p>
<p>CTF学习系列文章:</p>
<ul>
<li><a href="https://blog.shijy16.cn/2021/05/11/CTF/ctf%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">ctf学习笔记</a>: 学习CTF的笔记，主要按照《从0到1:CTFer的成长之路》书中内容学习。</li>
<li><a href="https://blog.shijy16.cn/2021/05/12/CTF/CTF%E8%A7%A3%E9%A2%98%E8%AE%B0%E5%BD%95/">CTF解题记录</a>: 《从0到1:CTFer的成长之路》配套平台的题目解题步骤。</li>
<li><a href="https://blog.shijy16.cn/2021/05/12/CTF/CTF%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E9%A2%98%E7%9B%AEWP/">CTF学习过程中的题目WP</a>:学习CTF过程中遇到的题目的WP。</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>CTF</tag>
      </tags>
  </entry>
  <entry>
    <title>CTF学习过程中的题目WP</title>
    <url>/2021/05/13/CTF/CTF%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E9%A2%98%E7%9B%AEWP/</url>
    <content><![CDATA[<p><object data="./writeup.pdf" type="application/pdf" width="100%" height="900px">This browser does not support PDFs. Please download the PDF to view it: <a href="/index.pdf">Download PDF</a><br></object></p>
<p>文中latex源码、提到的题目、源码、writeup均位于<a href="https://github.com/shijy16/learn-ctf%E3%80%82">https://github.com/shijy16/learn-ctf。</a></p>
<p>CTF学习系列文章:</p>
<ul>
<li><a href="https://blog.shijy16.cn/2021/05/11/CTF/ctf%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">ctf学习笔记</a>: 学习CTF的笔记，主要按照《从0到1:CTFer的成长之路》书中内容学习。</li>
<li><a href="https://blog.shijy16.cn/2021/05/12/CTF/CTF%E8%A7%A3%E9%A2%98%E8%AE%B0%E5%BD%95/">CTF解题记录</a>: 《从0到1:CTFer的成长之路》配套平台的题目解题步骤。</li>
<li><a href="https://blog.shijy16.cn/2021/05/12/CTF/CTF%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E9%A2%98%E7%9B%AEWP/">CTF学习过程中的题目WP</a>:学习CTF过程中遇到的题目的WP。</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>CTF</tag>
      </tags>
  </entry>
  <entry>
    <title>ctf学习笔记</title>
    <url>/2021/05/13/CTF/ctf%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p><object data="./note.pdf" type="application/pdf" width="100%" height="900px">This browser does not support PDFs. Please download the PDF to view it: <a href="/index.pdf">Download PDF</a><br></object></p>
<p>文中latex源码、提到的题目、源码、writeup均位于<a href="https://github.com/shijy16/learn-ctf%E3%80%82">https://github.com/shijy16/learn-ctf。</a></p>
<p>CTF学习系列文章:</p>
<ul>
<li><a href="https://blog.shijy16.cn/2021/05/11/CTF/ctf%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">ctf学习笔记</a>: 学习CTF的笔记，主要按照《从0到1:CTFer的成长之路》书中内容学习。</li>
<li><a href="https://blog.shijy16.cn/2021/05/12/CTF/CTF%E8%A7%A3%E9%A2%98%E8%AE%B0%E5%BD%95/">CTF解题记录</a>: 《从0到1:CTFer的成长之路》配套平台的题目解题步骤。</li>
<li><a href="https://blog.shijy16.cn/2021/05/12/CTF/CTF%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E9%A2%98%E7%9B%AEWP/">CTF学习过程中的题目WP</a>:学习CTF过程中遇到的题目的WP。</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>CTF</tag>
      </tags>
  </entry>
  <entry>
    <title>Fuzz with GPU</title>
    <url>/2021/07/04/fuzz/Fuzz-with-GPU/</url>
    <content><![CDATA[<h1 id="Let’s-build-a-high-performance-fuzzer-with-GPUs"><a href="#Let’s-build-a-high-performance-fuzzer-with-GPUs" class="headerlink" title="Let’s build a high-performance fuzzer with GPUs!"></a>Let’s build a high-performance fuzzer with GPUs!</h1><p>Trails of Bits的一篇博客，<a href="https://blog.trailofbits.com/2020/10/22/lets-build-a-high-performance-fuzzer-with-gpus/">原文</a>。</p>
<p><em>by <a href="https://reberhardt.com/blog">Ryan Eberhardt</a>, Stanford University</em></p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><ul>
<li>GPU算力价格便宜</li>
<li>GPU适合执行并行执行</li>
<li>fuzz很容易并行化</li>
<li>目标：使用GPU达到十倍速度</li>
</ul>
<h2 id="使用GPU的挑战"><a href="#使用GPU的挑战" class="headerlink" title="使用GPU的挑战"></a>使用GPU的挑战</h2><ul>
<li>GPU不能直接执行x86/arch67等指令<ul>
<li>目标是fuzz无源码的嵌入式软件，无法直接放到GPU中执行。</li>
</ul>
</li>
<li>GPU没有操作系统<ul>
<li>没有进程间地址空间隔离的概念，一个进程崩溃，会影响其他进程，需要进行进程间隔离。</li>
<li>没有系统调用，如文件打开、使用网络等，必须在GPU中模拟系统调用或使用CPU进行中继。</li>
</ul>
</li>
<li>GPU内存难以管理<ul>
<li>有复杂的内存层次，性能高度依赖内存访问模式</li>
<li>内存不够：16G GPU内存分给要同时执行40k线程时，每个线程只有约419kB</li>
</ul>
</li>
</ul>
<h2 id="通过二进制翻译在GPU执行代码"><a href="#通过二进制翻译在GPU执行代码" class="headerlink" title="通过二进制翻译在GPU执行代码"></a>通过二进制翻译在GPU执行代码</h2><p>可以从原始二进制代码翻译到IR，再翻译到PTX。</p>
<ul>
<li>使用Trail of Bits的工具Remill，将二进制”lift”为LLVM IR</li>
<li>LLVM支持将LLVM IR转换为PTX代码</li>
</ul>
<p><img src="white-3-remill.png" alt="white-3-remill"></p>
<h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><p>实现了一个MMU:</p>
<ul>
<li>使用remill替换读写操作，进行读写检查，同时拦截错误操作，防止整个fuzzer崩溃，保证进程间内存的独立</li>
<li>使用COW机制保证内存够用</li>
</ul>
<h2 id="初始性能"><a href="#初始性能" class="headerlink" title="初始性能"></a>初始性能</h2><p><img src="intrinsics-compilation.png" alt="intrinsics-compilation"></p>
<p>使用remill转换为LLVM IR，而后使用llvm转换为PTX，且通过remill修改read和write，从而加上MMU功能，就可以把aarch64程序放到GPU上并行执行了，由于没有实现突变器等组件，目前通过每秒执行次数来衡量性能。</p>
<p>以libpcap的BPF包为benchmark进行测试，原因如下：</p>
<ul>
<li>其状态机对于人类来说过于复杂，不适合人类推导，适合fuzz</li>
<li>BPF曾经有Bug，是适合fuzz的真实程序</li>
<li>没有系统调用</li>
</ul>
<p>实现了一个简单的、从fuzzer获取包的应用，并且执行如下BPF过滤程序：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">dst host 1.2.3.4 or tcp or udp or ip or ip6 or arp or rarp</span><br><span class="line">or atalk or aarp or decnet or iso or stp or ipx</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>和libFuzzer相比性能如下：</p>
<p><img src="graphs.001.jpeg" alt="graphs.001"></p>
<h2 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h2><h5 id="优化内存访问"><a href="#优化内存访问" class="headerlink" title="优化内存访问"></a>优化内存访问</h5><p>大多计算资源一直处于空闲状态，发现主要时间开销在访存上，之前一个warp内各个线程内存分开分配的，导致访存无法合并。</p>
<p>为此，进行了优化，将一个warp内的线程同时需要的内存放在了一起。</p>
<p>结果效率提高了一个数量级。</p>
<h5 id="减少数据传输和kernel启动"><a href="#减少数据传输和kernel启动" class="headerlink" title="减少数据传输和kernel启动"></a>减少数据传输和kernel启动</h5><p>之前直接使用统一内存在两个round间同步传输数据，导致数据传输开销很大，可以通过直接启动一个GPU kernel、避免CPU-GPU同步数据来解决。</p>
<ul>
<li>直接分配全局内存在GPU侧</li>
<li>round间在GPU侧对内存进行初始化</li>
<li>只和CPU异步传输必要的模糊测试信息，如导致crash的输入</li>
</ul>
<p>最后的效果图如下，baseline是最初的实现，Interleaved是做了内存访问优化后的，Better transfers是做了内存传输优化后的。</p>
<p><img src="graphs.003.jpeg" alt="graphs.003"></p>
<h2 id="What’s-Next"><a href="#What’s-Next" class="headerlink" title="What’s  Next"></a>What’s  Next</h2><ul>
<li>硬件利用率仍然很低，内存还有进一步优化空间</li>
<li>系统调用还需要处理</li>
</ul>
<h1 id="More-thoughts"><a href="#More-thoughts" class="headerlink" title="More thoughts"></a>More thoughts</h1><p>GPU控制单元少、ALU多，适合计算型任务，单独运行CPU程序会很慢，但是如果以数千个线程并行运行CPU任务，或许会比在CPU上运行数千次快很多。</p>
<p>并行方法有两种：</p>
<ul>
<li>全并行：整个程序转换为PTX代码，并行运行。</li>
<li>部分并行：程序部分计算任务转换为PTX代码，运行数千次程序至该任务前sync一下，而后将计算任务统一放到GPU上执行。</li>
</ul>
<p>Challenges:</p>
<ul>
<li>内存管理:<ul>
<li>修改内存布局，以适应GPU访存模式</li>
<li>内存复用，不可能每个线程分配一遍内存，这会导致内存不够用</li>
</ul>
</li>
<li>二进制翻译</li>
<li>系统调用的处理</li>
</ul>
<p>更多：</p>
<ul>
<li>fuzz中很多计算过程都会重复，如何去除这些重复？</li>
<li>内存重复，如何去除？</li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>GPU</tag>
        <tag>fuzz</tag>
      </tags>
  </entry>
  <entry>
    <title>Spectre Attack论文阅读</title>
    <url>/2021/05/17/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E6%94%BB%E5%87%BB/SepctreAttack%E9%98%85%E8%AF%BB%E6%8A%A5%E5%91%8A/</url>
    <content><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>这篇文章描述的是大名鼎鼎的幽灵攻击，一种利用分支预测机制的侧信道攻击方法，可以从受害进程中读取任意内存。</p>
<p>分支预测(投机执行)在预测错误情况下执行了不该执行的逻辑，访问了不该访问的内存和寄存器。尽管CPU进行了状态回退，仍存在副作用，可能从侧信道泄露机密信息。</p>
<p>实际上，分支预测的实现与很多现有安全机制依赖的安全假设相悖，如操作系统线程分离、容器化、即时编译和缓存定时、侧信道攻击的防御机制。对现有的数十亿Intel、AMD、ARM设备带来了严重威胁。</p>
<p>这篇文章主要介绍的是幽灵攻击最主要的两个变体:</p>
<ul>
<li>变体1 CVE-2017-5753: Bound Check Bypass</li>
<li>变体2 CVE-2017-5715: Branch Target Injection</li>
</ul>
<h1 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h1><p>幽灵攻击主要利用分支预测技术和缓存侧信道攻击方法在受害进程中读取任意内存。本节对这篇文章主要利用的分支预测技术和主要利用的缓存侧信道攻击技术进行介绍。</p>
<h2 id="分支预测"><a href="#分支预测" class="headerlink" title="分支预测"></a>分支预测</h2><p>遇到条件分支语句时，CPU会对分支方向进行猜测，不会暂停等待分支结果被计算出来。当猜测正确时，CPU会提交预测执行的结果，并继续执行下去，可以节省大量的时间，当猜测错误时，CPU会回退到预测执行之前的状态，从正确的分支方向开始执行。一般而言，CPU可以提前预测运行数百条指令，该限制由CPU中reorder<br>buffer决定。在微体系结构中，指令被划分为micro-ops，在Haswell微体系结构中，reorder<br>buffer可以容纳192个micro-ops。</p>
<p>Intel会对如下指令进行预测:</p>
<ul>
<li><p>  直接调用和跳转。</p>
</li>
<li><p>  间接调用和跳转。</p>
</li>
<li><p>  条件分支。</p>
</li>
</ul>
<p>分支预测方法一共分为三种:</p>
<ul>
<li><p>  静态预测:总是预测分支会/不会发生跳转。</p>
</li>
<li><p>  单调预测:总是预测分支向地址更高/低的方向继续执行。</p>
</li>
<li><p>  动态预测:根据近期程序行为进行预测。</p>
</li>
</ul>
<p>主要分支预测组件为:</p>
<ul>
<li>Branch Target Buffer(BTB):存放每个分支指令的跳转目标地址低位，一般用分支指令地址的低位进行索引。</li>
<li>  Branch History Buffer(BHB):存放近期分支历史。</li>
</ul>
<p>在动态分支预测时，分支预测器会利用BTB和BHB、结合分支预测算法，对分支方向进行预测，并从BTB中获取分支地址。BTB和BHB是一个核内所有线程共享的。</p>
<h2 id="缓存侧信道攻击"><a href="#缓存侧信道攻击" class="headerlink" title="缓存侧信道攻击"></a>缓存侧信道攻击</h2><p>本文利用的缓存侧信道攻击方法主要为flush+reload方法和evict+reload方法，这两个方法首先清空攻击者和受害者共享的一大块缓存区域，等待受害者执行一段时间后，通过衡量读取该区域内每个缓存行需要的时间来确定攻击者在这段时间内访问了哪些缓存行，若被访问缓存行对应的地址中含有机密信息，攻击者就可以通过这个方法恢复出机密信息。</p>
<p>flush+reload方法和evict+reload方法的区别在于前者通过clflush指令清空缓存区域，后者通过竞争的方式清空缓存区域。</p>
<h2 id="本文方法"><a href="#本文方法" class="headerlink" title="本文方法"></a>本文方法</h2><p>本文章将误导分支预测器进行错误预测，导致恶意代码被预测执行(在变体2中通过注入BTB来控制控制流到恶意代码)，哪怕CPU发现预测错误然后恢复状态以后，数据也从缓存侧信道泄露，然后本文利用缓存侧信道攻击方法从缓存中恢复泄露的数据，从而达到读取任意数据的目的。</p>
<h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><p>meltdown攻击和spectre attack一样，也是一种微体系结构层面的侧信道攻击，都利用了CPU投机执行的机制，它们的不同之处在于:</p>
<ul>
<li><p>  meltdown利用乱序执行时，CPU忽略了权限检查，可以读取内核地址。打破的是内核和用户之间的隔离。</p>
</li>
<li><p>spectre利用了分支预测，可以读取其他进程的地址空间。打破的是进程间的隔离。</p>
</li>
<li><p>meltdown 主要作用于intel<br>  CPU。现代CPU普遍采用分支预测技术，所以spectre作用范围更广。</p>
</li>
</ul>
<h1 id="研究内容"><a href="#研究内容" class="headerlink" title="研究内容"></a>研究内容</h1><p>这篇文章主要研究内容是幽灵攻击，介绍了最主要的两个变体:</p>
<ul>
<li><p>  变体1 CVE-2017-5753: Bound Check Bypass</p>
</li>
<li><p>  变体2 CVE-2017-5715: Branch Target Injection</p>
</li>
</ul>
<p>变体1通过误导分支预测器，绕过边界检查，导致CPU执行不该执行的分支，读取不该读取的数据，CPU状态恢复之后，攻击者从缓存中恢复该读取的数据，从达到读取任意地址的目的。变体2通过注入BTB和误导分支预测器，劫持控制流到gadget，导致gadget被瞬态执行，读取攻击者想要读取的数据，然后从缓存中恢复该数据，从而读取任意地址。</p>
<h1 id="方法实现"><a href="#方法实现" class="headerlink" title="方法实现"></a>方法实现</h1><h2 id="攻击总览"><a href="#攻击总览" class="headerlink" title="攻击总览"></a>攻击总览</h2><p>整个攻击主要思路为:</p>
<ul>
<li><p>  诱使受害者进行推测执行。</p>
</li>
<li><p>  利用缓存信道泄露受害者机密信息。</p>
</li>
</ul>
<p>整个攻击可分为三个阶段。</p>
<h4 id="阶段一"><a href="#阶段一" class="headerlink" title="阶段一"></a>阶段一</h4><p>setup阶段，主要工作为:</p>
<ul>
<li><p>  训练处理器，使其进行可利用的错误的分支预测。</p>
</li>
<li><p>  进行一些操作，使得推测执行更容易发生，如控制cache，清除处理器确定实际控制流所需要的数据。</p>
</li>
<li><p>  准备秘密信道: 进行Flush+Reload或Evict+Rload的清空缓存部分。</p>
</li>
</ul>
<h4 id="阶段二"><a href="#阶段二" class="headerlink" title="阶段二"></a>阶段二</h4><p>让处理器推测执行指令，使受害者的机密信息从其上下文中被存放到机密信道。可能进行的工作为:</p>
<ul>
<li><p>  攻击者请求受害者执行某种操作，从而触发推测执行，如系统调用、socket、文件等。</p>
</li>
<li><p>  或在自己的代码中推测执行，以获取同一进程中的敏感信息。如在解释器、JIT编译器、安全语言的沙箱中获取敏感信息。</p>
</li>
</ul>
<p>推测执行把敏感数据暴露在了机密信道，如cache中。所以推测执行中可以读取一个攻击者给定的地址的值，然后把这个值作为地址的一部分，对该地址进行内存操作，改变其对应cache状态，从而暴露这个值。</p>
<h4 id="阶段三"><a href="#阶段三" class="headerlink" title="阶段三"></a>阶段三</h4><p>通过Flush+Reload或Evict+Rload恢复秘密值。</p>
<h2 id="变体1"><a href="#变体1" class="headerlink" title="变体1"></a>变体1</h2><p>变体1假定攻击者想要读取同一线程中原本无法读取的区域。变体1POC如图所示，变体1通过训练分支预测器，即多次使用合法的offset运行该代码片段，导致if分支被误导，使得在后续攻击者使用不合法的offset调用该代码片段时，后续代码被预测执行，将<em>s<strong>i</strong>g<strong>n</strong>a**l</em> + <em>i<strong>n</strong>d<strong>e</strong>x</em>2地址的值读取到cache中，哪怕该代码片段最后会被回退，signal+ index2地址对应的缓存行仍然会保存在cache中，攻击者可以通过flush+reload方法获取index2的值，从而得到value的值(一个攻击者无法访问的机密值)。</p>
<img src="1.jpg" alt="变体1示例" style="width:80.0%" />

<p>变体1的应用场景为javascript等沙箱和即时编译器、解释器场景中，变体1可以应用在eBPF接口中读取内核地址。</p>
<h2 id="变体2"><a href="#变体2" class="headerlink" title="变体2"></a>变体2</h2><p>在变体2中，假定攻击者和受害者是统一进程的两个线程，攻击者想要读取受害者的内存，如图 。攻击者可以找到受害者地址空间中的一个gadget(通常在共享库中)和选取受害者的一个间接分支指令为注入目标。在自身地址空间的相同位置的间接分支指令处不断跳转到gadget在受害者地址空间中的地址，从而导致受害者的目标间接分支指令对应BTB表项被注入为gadget地址，受害者执行该间接分支指令时，会发生预测执行gadget，攻击者可以利用该gadget完成一些读取操作，配合后续的flush+reload。</p>
<img src="2.jpg" alt="变体2:间接分支毒化" style="width:80.0%" />

<h4 id="gadget"><a href="#gadget" class="headerlink" title="gadget"></a>gadget</h4><p>gadget需要选取攻击者能够控制其中两个寄存器的(部分情况下一个寄存器也够用)代码片段，如下:</p>
<pre><code>add/xor/... R2,[R1]
access R2
</code></pre>
<p>然后就可以通过flush+reload方法恢复出[R1]的值。<br>变体2相比变体1更灵活。作者还提出了通过变体2在虚拟机中读取host主机地址空间的方法。</p>
<h3 id="攻击KVM"><a href="#攻击KVM" class="headerlink" title="攻击KVM"></a>攻击KVM</h3><p>逆向分析Intel<br>Haswell分支预测器内部，以准备对KVM进行攻击。作者使用同一核上的两个超线程进行实验，完成逆向:</p>
<ul>
<li><p>  Hyperthread A: jump指令跳转到Address 1。</p>
</li>
<li><p>  Hyperthread B: jump指令跳转到Address 2。</p>
</li>
<li><p>  A中Address 2处放着load一个缓存行的代码。</p>
</li>
<li><p>  用flush&amp;reload方法统计那个缓存行被加载的频率，计算错误预测率，从而探索分支预测算法。</p>
</li>
</ul>
<p>逆向结果:</p>
<p>2 <img src="3.jpg" alt="image" /><br><img src="4.jpg" alt="image" /></p>
<p>攻击KVM的方法:假设攻击者有guest VM的完全控制权限，包括ring0，想要读取host内存地址。</p>
<ul>
<li><p>通过分析BTB和BHB泄露的信息来获取：</p>
<ul>
<li><p>hypervisor ASLR后的地址：Jump over ASLR: Attacking branch<br>  predictors to bypass ASLR</p>
</li>
<li><p>找到L3 cache集关联信息：Last-Level Cache Side-Channel Attacks<br>  are Practical</p>
</li>
<li><p>  物理内存位置映射信息: 通过分支注入spctre gadget来获取。</p>
</li>
</ul>
</li>
<li><p>  通过在hypervisor内存执行eBPF解释器来作为gadget，使用针对间接分支主要预测机制为目标的间接分支注入的方法，来泄露hypervisor的内存。</p>
</li>
</ul>
<p>这一部分我没有看懂，在网上找到了稍微易懂一点的下图:</p>
<img src="5.jpg" alt="VM攻击host" style="width:80.0%" />

<p>图片来源于<a href="https://www.youtube.com/watch?v=zYRI60uAwYc">youtube</a></p>
<h1 id="防御措施"><a href="#防御措施" class="headerlink" title="防御措施"></a>防御措施</h1><p>防御措施可以分为五个方向去做:</p>
<ul>
<li><p>防止推测执行。</p>
<ul>
<li><p>  未来可以允许软件禁用推测执行，或者硬件可以切换到禁止推测执行模式。但不能在当前立即解决问题。</p>
</li>
<li><p>  修改软件来串行执行或使用禁止推测指令来保证后续指令不会被推测执行。在分支指令的两个分支方向都放置ifence指令。</p>
</li>
<li><p>  在间接分支之前插入Ifence，可以确保清空分支之前的流水线，保证该分支被快速解决，从而减少推测执行的指令数量。</p>
</li>
</ul>
</li>
<li><p>防止敏感数据泄露:<br>  进程间隔离、数组边界检查、指针毒化。对JIT编译器、解释器最有用。</p>
</li>
<li><p>防止数据进入机密信道:<br>  未来处理器可以检测推测执行是否获取了数据，并阻止该数据被用于之后的操作。</p>
</li>
<li><p>防止从机密信道提取数据:<br>  如javascript降低了计时器的精度，还有概率添加抖动。只能降低攻击性能，不能杜绝攻击。当前处理器没办法完全消除隐蔽信道。</p>
</li>
<li><p>防止间接分支毒化-Intel和AMD指令集架构的控制间接分支的机制:</p>
<ul>
<li><p>Indirect Branch Restricted Speculation (IBRS):<br>  间接分支限制推测，防止特权级高的间接分支被特权级低的间接分支影响。IBRS模式中的处理器不受IBRS模式外的计算影响。</p>
</li>
<li><p>Single Thread Indirect Branch Prediction (STIBP):<br>  限制在同一内核的超线程上执行的软件之间的分支预测共享。</p>
</li>
<li><p>Indirect Branch Predictor Barrier (IBPB):<br>  防止在设置屏障之前运行的软件影响在屏障之后运行的软件的分支预测（通过刷新BTB状态）。</p>
</li>
</ul>
</li>
<li><p>防止间接分支毒化-google的retpolines:用ret指令替换所有的间接分支，相当于禁用分支预测。</p>
<ul>
<li>  Intel为一些处理器发布了micro-code更新，禁用return指令fall-back到BTB进行预测的机制。</li>
</ul>
</li>
</ul>
<p>要解决这个问题需要从根本上改变指令集体系结构，需要在安全性和性能之间做权衡取舍。</p>
]]></content>
      <categories>
        <category>论文阅读笔记</category>
      </categories>
      <tags>
        <tag>CPU体系结构攻击</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客搭建</title>
    <url>/2021/05/13/%E9%85%8D%E7%BD%AE/Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h2 id="Hexo环境安装"><a href="#Hexo环境安装" class="headerlink" title="Hexo环境安装"></a>Hexo环境安装</h2><h3 id="安装node-js"><a href="#安装node-js" class="headerlink" title="安装node.js"></a>安装node.js</h3><p>下载安装<a href="https://nodejs.org/">node.js</a></p>
<p>更换国内源:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm config set registry https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>

<h3 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir blog &amp;&amp; cd blog	#创建hexo目录</span><br><span class="line">npm i hexo-cli -g		#安装hexo</span><br><span class="line">hexo -v					#验证是否成功</span><br><span class="line">hexo init				#初始化</span><br><span class="line">npm install				#安装必备库</span><br></pre></td></tr></table></figure>

<h3 id="网页基本操作"><a href="#网页基本操作" class="headerlink" title="网页基本操作"></a>网页基本操作</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo g				#生成网页</span><br><span class="line">hexo s				#创建本地服务器</span><br><span class="line">hexo clean			#clean</span><br><span class="line">hexo new post &quot;article title&quot;	#创建新文章</span><br></pre></td></tr></table></figure>

<p>至此，hexo基本环境安装完成。</p>
<h2 id="next主题安装和背景设置"><a href="#next主题安装和背景设置" class="headerlink" title="next主题安装和背景设置"></a>next主题安装和背景设置</h2><h3 id="安装next"><a href="#安装next" class="headerlink" title="安装next"></a>安装next</h3><p>下载next主题:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/theme-next/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>

<p>在<code>_config.yml</code>中修改<code>theme</code>属性为:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">theme: next</span><br></pre></td></tr></table></figure>

<h3 id="设置背景图片"><a href="#设置背景图片" class="headerlink" title="设置背景图片"></a>设置背景图片</h3><ul>
<li>将背景图片<code>bg.jpg</code>复制到<code>themes\next\source\images</code>中</li>
</ul>
<p>在<code>themes/next/_config.yml</code>中取消注释:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">style: source/_data/styles.styl</span><br></pre></td></tr></table></figure>

<p>并在根目录下的<code>source</code>文件夹创建<code>_data/styles.styl</code>，在<code>styles.styl</code>中添加:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">body &#123;</span><br><span class="line"> 	background:url(/images/bg.jpg);</span><br><span class="line"> 	background-repeat: no-repeat;</span><br><span class="line">    background-attachment:fixed;</span><br><span class="line">    background-position:50% 50%;</span><br><span class="line">    background-size: cover;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>背景图片会铺满整个页面</p>
<h3 id="设置文章透明度"><a href="#设置文章透明度" class="headerlink" title="设置文章透明度"></a>设置文章透明度</h3><p>默认所有内容背景透明，看不清字，所以需要设置文章背景透明度:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.main-inner &#123; </span><br><span class="line">    margin-top: 60px;</span><br><span class="line">    padding: 60px 60px 60px 60px;</span><br><span class="line">    background: rgba(255,255,255,0.9);</span><br><span class="line">    min-height: 500px;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//博客内容透明化</span><br><span class="line">.content-wrap&#123;</span><br><span class="line">  opacity: 0.9;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//侧边框的透明度设置</span><br><span class="line">.sidebar &#123;</span><br><span class="line">  opacity: 0.9;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//菜单栏的透明度设置</span><br><span class="line">.header-inner &#123;</span><br><span class="line">  background: rgba(255,255,255,0.9);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//搜索框（local-search）的透明度设置</span><br><span class="line">.popup &#123;</span><br><span class="line">  opacity: 0.9;</span><br><span class="line">&#125;</span><br><span class="line">.footer-inner &#123;</span><br><span class="line">  background: rgba(255,255,255,0.9);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="主题相关设置"><a href="#主题相关设置" class="headerlink" title="主题相关设置"></a>主题相关设置</h2><h3 id="修改整体scheme"><a href="#修改整体scheme" class="headerlink" title="修改整体scheme"></a>修改整体scheme</h3><p>默认Muse有点丑，在<code>next</code>文件夹下的<code>config</code>中改为其他<code>scheme</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Schemes</span><br><span class="line"># scheme: Muse</span><br><span class="line"># scheme: Mist</span><br><span class="line">scheme: Pisces</span><br><span class="line"># scheme: Gemini</span><br></pre></td></tr></table></figure>

<p>这里直接修改后在本地看起来没问题，部署到<code>github.io</code>上侧边栏就会出错，查了一下发现是设置里自带了<code>sidebar</code>属性，两个会冲突，所以修改<code>next</code>的配置文件中的<code>sidebar</code>为<code>hide</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sidebar:</span><br><span class="line">  display: hide</span><br></pre></td></tr></table></figure>

<p>问题解决。</p>
<p>因为该scheme自带了一个<code>content-wraper</code>，所以透明度需要修改，把 <code>themes\next\source\css\_schemes\Pisces\_layout.styl</code> 文件 <code>.content-wrap</code> 标签下 <code>background: white</code>改为完全透明:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">background: rgba(255,255,255,0);</span><br></pre></td></tr></table></figure>

<p>然后根目录下<code>source/_data/_styles.styl</code>中的透明度设置:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.main-inner &#123; </span><br><span class="line">    margin-top: 60px;</span><br><span class="line">    padding: 60px 60px 60px 60px;</span><br><span class="line">    background: rgba(255,255,255,0.9);</span><br><span class="line">    min-height: 500px;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//侧边框的透明度设置</span><br><span class="line">.sidebar &#123;</span><br><span class="line">  opacity: 0.9;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//菜单栏的透明度设置</span><br><span class="line">.header-inner &#123;</span><br><span class="line">  background: rgba(255,255,255,0.9);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//搜索框（local-search）的透明度设置</span><br><span class="line">.popup &#123;</span><br><span class="line">  opacity: 0.9;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">.footer-inner &#123;</span><br><span class="line">  background: rgba(255,255,255,0.8);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="添加分类和标签"><a href="#添加分类和标签" class="headerlink" title="添加分类和标签"></a>添加分类和标签</h3><p>创建分类和标签页面:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new page categories</span><br><span class="line">hexo new page tags</span><br></pre></td></tr></table></figure>

<p>分别编辑 <code>categories/index.md</code> 和 <code>tags/index.md</code> 文件，将内容替换为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 分类</span><br><span class="line">date: 2021-05-10 12:22:12</span><br><span class="line">type: &quot;categories&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<p>和</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 标签</span><br><span class="line">date: 2021-05-10 12:21:48</span><br><span class="line">type: &quot;tags&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<p>配置<code>themes/_config.yml</code>中的菜单属性:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">  home: / || home</span><br><span class="line">  #about: /about/ || user</span><br><span class="line">  tags: /tags/ || tags</span><br><span class="line">  categories: /categories/ || th</span><br><span class="line">  archives: /archives/ || archive</span><br><span class="line">  #schedule: /schedule/ || calendar</span><br><span class="line">  #sitemap: /sitemap.xml || sitemap</span><br><span class="line">  #commonweal: /404/ || heartbeat</span><br></pre></td></tr></table></figure>

<p>完成后就可以设置文章的属性和标签了:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">title: Hexo博客搭建</span><br><span class="line">date: 2021-05-11 22:38:54</span><br><span class="line">tags: 教程</span><br><span class="line">categories: 其他</span><br></pre></td></tr></table></figure>

<p>多标签:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tags: [教程,其他]</span><br></pre></td></tr></table></figure>

<h3 id="限制目录深度标题"><a href="#限制目录深度标题" class="headerlink" title="限制目录深度标题"></a>限制目录深度标题</h3><p>修改<code>themes/_config.yml</code>中的<code>max_depth</code>属性为<code>3</code></p>
<h3 id="侧边栏社交信息"><a href="#侧边栏社交信息" class="headerlink" title="侧边栏社交信息"></a>侧边栏社交信息</h3><p>修改<code>themes/_config.yml</code>中的<code>social</code>属性</p>
<h3 id="首页不显示全文"><a href="#首页不显示全文" class="headerlink" title="首页不显示全文"></a>首页不显示全文</h3><p>在每个文章头添加<code>description</code>属性。</p>
<h3 id="更改网站图标"><a href="#更改网站图标" class="headerlink" title="更改网站图标"></a>更改网站图标</h3><p>找一张想做图标的图，在<a href="http://www.bitbug.net/">bitbug</a>里生成<code>16x16</code>和<code>32x32</code>的各一张，然后放到<code>next</code>里面的<code>source/images</code>文件下。</p>
<p>然后配置next主题的<code>config</code>文件，修改favicon:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">favicon:</span><br><span class="line">small: /images/my16x16.png</span><br><span class="line">medium: /images/my32x32.png</span><br></pre></td></tr></table></figure>

<h3 id="更改个人头像"><a href="#更改个人头像" class="headerlink" title="更改个人头像"></a>更改个人头像</h3><p>把放到<code>next</code>里面的<code>source/images</code>文件下，然后配置next主题的<code>config</code>文件，修改avatar:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">avatar:</span><br><span class="line">  # Replace the default image and set the url here.</span><br><span class="line">  url: /images/avatar.jpg</span><br></pre></td></tr></table></figure>

<h5 id="更改网站签名"><a href="#更改网站签名" class="headerlink" title="更改网站签名"></a>更改网站签名</h5><p>在根部录下的<code>config</code>文件中，修改<code>description</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">description: &#x27;I am a noob.&#x27;</span><br></pre></td></tr></table></figure>

<h2 id="功能相关设置"><a href="#功能相关设置" class="headerlink" title="功能相关设置"></a>功能相关设置</h2><h3 id="添加本地搜索功能"><a href="#添加本地搜索功能" class="headerlink" title="添加本地搜索功能"></a>添加本地搜索功能</h3><p>在hexo的根目录下执行命令：<code>npm install hexo-generator-searchdb --save</code></p>
<p>在根目录下的<code>_config.yml</code>文件中添加配置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">search:</span><br><span class="line">  path: search.xml</span><br><span class="line">  field: post</span><br><span class="line">  format: html</span><br><span class="line">  limit: 10000</span><br></pre></td></tr></table></figure>

<p>在修改<code>next</code>目录下的<code>config</code>文件中的<code>local_search</code>为<code>enable</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">local_search:</span><br><span class="line">  enable: true</span><br></pre></td></tr></table></figure>

<h3 id="访客统计"><a href="#访客统计" class="headerlink" title="访客统计"></a>访客统计</h3><p>修改<code>themes/_config.yml</code>中的<code>busuanzi_count</code>为<code>enable</code></p>
<h3 id="添加评论功能"><a href="#添加评论功能" class="headerlink" title="添加评论功能"></a>添加评论功能</h3><h5 id="Valine"><a href="#Valine" class="headerlink" title="Valine"></a>Valine</h5><p>使用<strong>Valine 评论系统</strong>，访客不需要登录即可评论，而且支持markdown。</p>
<p>首先注册一个账号:<a href="https://leancloud.cn/dashboard/login.html#/signin">LeanCloud官网登录入口</a>。注册后访问控制台，创建开发版应用，在设置中获取 <code>App ID</code> 和 <code>App Key</code>。在next的config文件中，修改<code>valine</code>相关配置:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Valine.</span><br><span class="line"># You can get your appid and appkey from https://leancloud.cn</span><br><span class="line"># more info please open https://valine.js.org</span><br><span class="line">valine:</span><br><span class="line">  enable: true # 是否开启</span><br><span class="line">  appid:   # 上一步获取的 App ID</span><br><span class="line">  appkey:  # 上一步获取的 App Key</span><br><span class="line">  notify: false # 新留言是否需要通知 https://github.com/xCss/Valine/wiki</span><br><span class="line">  verify: false # 是否需要验证，验证比较反人类建议false关闭</span><br><span class="line">  placeholder: 请在此输入您的留言 # 默认留言框内的文字</span><br><span class="line">  avatar: mm # 默认头像</span><br><span class="line">  guest_info: nick,mail # 默认留言框的头部需要访问者输入的信息</span><br><span class="line">  pageSize: 10 # pagination size #默认单页的留言条数</span><br></pre></td></tr></table></figure>

<h5 id="gitalk"><a href="#gitalk" class="headerlink" title="gitalk"></a>gitalk</h5><p>后面了解到还有gitalk评论系统，要求用github账户登录评论，基于仓库的issue实现，感觉这个更靠谱，就改成了这个。</p>
<p>注册gitalk应用，到[github申请页面](https : //github.com/settings/applications/new)申请，名称和描述随意填，两个url填自己博客地址，我的是<code>https://blog.shijy16.cn</code>，注册后，获得ID和Secret。</p>
<p>在next的config文件中，修改<code>gitalk</code>相关配置:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gitalk:</span><br><span class="line">  enable: true</span><br><span class="line">  github_id:  # GitHub repo owner</span><br><span class="line">  repo:  # Repository name to store issues</span><br><span class="line">  client_id: # GitHub Application Client ID</span><br><span class="line">  client_secret: # GitHub Application Client Secret</span><br><span class="line">  admin_user: # GitHub repo owner and collaborators, only these guys can initialize gitHub issues</span><br><span class="line">  distraction_free_mode: true # Facebook-like distraction free mode</span><br><span class="line">  # Gitalk&#x27;s display language depends on user&#x27;s browser or system environment</span><br><span class="line">  # If you want everyone visiting your site to see a uniform language, you can set a force language value</span><br><span class="line">  # Available values: en | es-ES | fr | ru | zh-CN | zh-TW</span><br><span class="line">  language:</span><br></pre></td></tr></table></figure>

<p>repo一般就直接填博客仓库名称就好了，<code>github_id</code>、<code>admin_user</code>就填自己的github id。然后记得把其他评论配置disable。</p>
<p>最后部署后，自己进入博客页面，查看文章末尾评论，应该会提示<code>issues not initailized</code>，点进去授权一下就可以了，在博客仓库里面的issue中看到gitalk自动创建的issue就代表配置成功。</p>
<h3 id="部署到github"><a href="#部署到github" class="headerlink" title="部署到github"></a>部署到github</h3><p>修改根目录下的配置文件最后一行的配置为:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: https://github.com/yourname/yourname.github.io</span><br><span class="line">  branch: main</span><br></pre></td></tr></table></figure>

<p>安装部署插件:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm i hexo-deployer-git</span><br></pre></td></tr></table></figure>

<p>部署:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure>

<h3 id="插入PDF"><a href="#插入PDF" class="headerlink" title="插入PDF"></a>插入PDF</h3><p>因为我用latex写的大部分笔记，所以有在网页中插入pdf这个需求。</p>
<p>在hexo中插入pdf有两个方案，第一种是用插件，我失败了，这里就不讲了(不管插入本地PDF还是远程PDF)。</p>
<p>这里讲第二种方案，用html。</p>
<p>首先在要插入文章的同级目录中创建文章同名文件夹，然后把PDF放进去:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-CTF学习笔记</span><br><span class="line">	-note.pdf</span><br><span class="line">-CTF学习笔记.md</span><br></pre></td></tr></table></figure>

<p>然后在markdown中插入:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;object data=&quot;./note.pdf&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;900px&quot;&gt;This browser does not support PDFs. Please download the PDF to view it: &lt;a href=&quot;/index.pdf&quot;&gt;Download PDF&lt;/a&gt;</span><br><span class="line">&lt;/object&gt;</span><br></pre></td></tr></table></figure>

<p>这里我还把根目录的<code>config</code>文件中的url属性改为了:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">url: https://shijy16.github.io</span><br></pre></td></tr></table></figure>

<p>然后就可以在博客中正常预览PDF了。</p>
<blockquote>
<p>PS: 尝试用远程PDF链接失败，用其他仓库中的PDF链接时，会直接弹出下载窗口，无法直接预览。</p>
<p>要直接预览的话需要为仓库创建github pages，但这样之后又不能方便更新了，和把pdf放到github.io仓库一样。</p>
<p>有解决方案的同学可以通过email联系我在后面评论。</p>
</blockquote>
<h3 id="个人域名重定向和HTTPS"><a href="#个人域名重定向和HTTPS" class="headerlink" title="个人域名重定向和HTTPS"></a>个人域名重定向和HTTPS</h3><p>首先在腾讯、阿里等域名代理商购买一个个人域名，我购买的是<code>shijy16.cn</code>，接下来对域名进行设置，使<code>blog.shijy16.cn</code>被解析到<code>shijy16.github.io</code>:</p>
<ul>
<li>添加CNAME记录，在域名控制台添加CNAME，将<code>blog.shijy16.cn</code>指向<code>shijy16.github.io</code></li>
<li>修改github pages设置，把<code>Custom domain</code>设为``blog.shijy16.cn`</li>
</ul>
<p>一段时间后可以正常从<code>blog.shijy16.cn</code>访问。</p>
<p>由于直接访问不是HTTPS链接，浏览器会提示不安全，可以用<a href="https://www.cloudflare.com/">CloudFlare</a> 提供的服务来强制使用HTTPS。</p>
<ul>
<li>注册CloudFlare账号，注册成功后在返回的页面中添加域名，点击扫描 DNS 记录，等待大约一分钟之后继续下一步。</li>
<li>添加域名解析，即把域名指向<code>github.io</code>，和之前的CNAME记录一样。</li>
<li>修改域名服务商中的DNS服务器为<a href="https://www.cloudflare.com/">CloudFlare</a> 的DNS服务器。</li>
<li>在<a href="https://www.cloudflare.com/">CloudFlare</a>引导下完成剩余步骤，重点是强制使用HTTPS访问。</li>
</ul>
<p>这一部分<a href="https://www.cloudflare.com/">CloudFlare</a>中有详细引导。完成之后，直接访问<a href="https://blog.shijy16.cn/2021/05/11/%E9%85%8D%E7%BD%AE/Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/blog.shijy16.cn">blog.shijy16.cn</a>就是HTTPS连接了。</p>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><blockquote>
<p><a href="https://www.dazhuanlan.com/2019/11/06/5dc26196564d8/">hexo目录设置</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/35668237">hexo+github博客搭建教程</a></p>
<p><a href="https://blog.qsong.fun/2018/01/31/next%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%E9%80%8F%E6%98%8E%E8%89%B2%E7%AD%89/">next主题配置透明色等</a></p>
<p><a href="https://chrischen0405.github.io/2018/09/11/post20180911/">hexo页脚添加访客人数和总访问量</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/35668237">超详细Hexo+Github博客搭建小白教程</a></p>
<p><a href="http://shenzekun.cn/hexo%E7%9A%84next%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B.html">hexo的next主题个性化配置教程</a></p>
<p><a href="https://xring.info/2018/hexo-category-and-tag-page.html">Hexo 博客创建 categories 和 tags 页面</a></p>
<p><a href="http://miracle778.site/pdf-test/pdf-test.html">hexo中插入pdf解决方法</a></p>
<p><a href="https://maiyang.me/post/2018-04-09-using-https-with-custom-domain-name-on-github-pages/">为 Github Pages 自定义域名博客开启 HTTPS</a></p>
<p><a href="https://yashuning.github.io/2018/06/29/hexo-Next-%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/">hexo - Next 主题添加评论功能</a></p>
<p><a href="https://blog.csdn.net/Olivia_Vang/article/details/92976637">更换Hexo的网页图标/小图片Hexo change page favicon</a></p>
<p><a href="https://blog.winsky.wang/Hexo%E5%8D%9A%E5%AE%A2/Hexo%E5%8D%9A%E5%AE%A2Next%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE/">Hexo博客Next主题配置</a></p>
<p><a href="https://www.cnblogs.com/Mayfly-nymph/p/10622307.html">Hexo解决页面过小问题与设置透明背景</a></p>
</blockquote>
]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>nvidia驱动和CUDA环境安装</title>
    <url>/2021/05/13/%E9%85%8D%E7%BD%AE/nvidia%E9%A9%B1%E5%8A%A8%E5%92%8CCUDA%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h2 id="卸载所有nvidia相关文件"><a href="#卸载所有nvidia相关文件" class="headerlink" title="卸载所有nvidia相关文件"></a>卸载所有nvidia相关文件</h2><p>一开始在安装了驱动后，安装CUDA的时候一直提示检测到驱动已安装，是否还要继续。搞得我很懵逼。又强行把所有nvidia驱动卸载了，不过正常安装前都需要把之前的所有nvidia相关软件卸了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt --purge remove *nvidia*</span><br><span class="line">sudo apt autoremove</span><br></pre></td></tr></table></figure>

<h2 id="禁用Nouveau-kernel-driver"><a href="#禁用Nouveau-kernel-driver" class="headerlink" title="禁用Nouveau kernel driver"></a>禁用Nouveau kernel driver</h2><p><code>Nouveau kernel driver</code>是一个开放源码显卡驱动程序，linux发行版自带，一般作为桌面程序默认的显卡驱动，在安装N卡驱动前 或后需要将该驱动屏蔽，强制系统使用新安装的N卡程序。</p>
<p>创建文件<code>/etc/modprobe.d/blacklist-nouveau.conf</code>，添加如下内容:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">blacklist lbm-nouveau</span><br><span class="line">options nouveau modeset=0</span><br><span class="line">alias nouveau off</span><br><span class="line">alias lbm-nouveau off</span><br></pre></td></tr></table></figure>

<p>然后执行<code>sudo update-initramfs -u</code>。</p>
<p>如果<code>xserver</code>在运行中，也需要先关闭<code>xserver</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">service lightdm stop</span><br></pre></td></tr></table></figure>

<h2 id="直接安装驱动和CUDA"><a href="#直接安装驱动和CUDA" class="headerlink" title="直接安装驱动和CUDA"></a>直接安装驱动和CUDA</h2><blockquote>
<p>我就是装了驱动后再装CUDA，然后装CUDA的时候一进去就提示检测到驱动，我以为是冲突了，就把所有驱动卸了，实际上应该不管这个提示，继续安装CUDA就好。</p>
</blockquote>
<p>驱动不需要手动安装，因为我在手动安装时提示可以自动安装，且自动安装的版本会更适合机器，所以直接自动安装驱动:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo ubuntu-drivers autoinstall</span><br></pre></td></tr></table></figure>

<p>然后重启系统:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure>

<p>确认安装正常:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>

<p>显示支持<code>11.2</code>版本的CUDA，到<a href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA下载页</a>找对应版本的CUDA，然后下载CUDA的<code>.run</code>安装文件:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/11.2.2/local_installers/cuda_11.2.2_460.32.03_linux.run</span><br><span class="line">sudo sh cuda_11.2.2_460.32.03_linux.run</span><br></pre></td></tr></table></figure>

<p>安装时首先会提示检测到安装了驱动，选择继续安装，在第二页取消勾选driver。继续安装即可。</p>
<p>安装完成后，在<code>~/.bashrc</code>中添加环境变量:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=&quot;/usr/local/cuda/lib64&quot;:$LD_LIBRARY_PATH</span><br><span class="line">export PATH=&quot;/usr/local/cuda/bin&quot;:$PATH</span><br></pre></td></tr></table></figure>

<p>使用<code>nvcc --version</code>查看是否安装成功。</p>
<h2 id="安装Cudnn"><a href="#安装Cudnn" class="headerlink" title="安装Cudnn"></a>安装Cudnn</h2><p>进入<a href="https://developer.nvidia.com/cudnn">cudnn</a>下载页，注册开发者账号填问卷后，下载压缩包，然后解压缩，进行如下拷贝和权限设置即可:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo cp cuda/include/cudnn.h /usr/local/cuda/include</span><br><span class="line">sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64</span><br><span class="line">sudo chmod a+r /usr/local/cuda/include/*.h </span><br><span class="line">sudo chmod a+r /usr/local/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure>

<h3 id="安装后解决问题-usr-local-cuda-lib64-libcudnn-so-is-not-a-static-symbol"><a href="#安装后解决问题-usr-local-cuda-lib64-libcudnn-so-is-not-a-static-symbol" class="headerlink" title="安装后解决问题: /usr/local/cuda/lib64/libcudnn*.so* is not a static symbol"></a>安装后解决问题: <code>/usr/local/cuda/lib64/libcudnn*.so* is not a static symbol</code></h3><p>安装后使用<code>ldconfig</code>的时候可能会有错误提示:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/sbin/ldconfig.real: /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8 is not a symbolic link</span><br><span class="line">/sbin/ldconfig.real: /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn.so.8 is not a symbolic link</span><br><span class="line">/sbin/ldconfig.real: /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8 is not a symbolic link</span><br><span class="line">/sbin/ldconfig.real: /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8 is not a symbolic link</span><br><span class="line">/sbin/ldconfig.real: /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8 is not a symbolic link</span><br><span class="line">/sbin/ldconfig.real: /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_adv_train.so.8 is not a symbolic link</span><br><span class="line">/sbin/ldconfig.real: /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_ops_train.so.8 is not a symbolic link</span><br></pre></td></tr></table></figure>

<p>可能是拷贝后静态链接被损坏导致的，需要一个一个解决，以<code>libcudnn.so</code>为例:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo rm libcudnn.so.8 libcudnn.so</span><br><span class="line">sudo ln libcudnn.so.8.2.0 libcudnn.so.8</span><br><span class="line">sudo ln libcudnn.so.8 libcudnn.so</span><br></pre></td></tr></table></figure>

<p>一个一个解决就好了。</p>
<h2 id="在cuda11-2下安装torch"><a href="#在cuda11-2下安装torch" class="headerlink" title="在cuda11.2下安装torch"></a>在cuda11.2下安装torch</h2><p>官方稳定版torch还没有支持11.2，需要手动编译源码安装。用Anaconda创建一个python3.9环境，然后安装依赖:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install numpy ninja pyyaml mkl mkl-include setuptools cmake cffi typing_extensions future six requests dataclasses</span><br></pre></td></tr></table></figure>

<p>获取pytorch并安装:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone --recursive https://github.com/pytorch/pytorch</span><br><span class="line">cd pytorch</span><br><span class="line"># if you are updating an existing checkout</span><br><span class="line">git submodule sync</span><br><span class="line">git submodule update --init --recursive</span><br><span class="line">export CMAKE_PREFIX_PATH=$&#123;CONDA_PREFIX:-&quot;$(dirname $(which conda))/../&quot;&#125;</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>

<p>之后python命令行中验证安装:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.__version__)</span><br><span class="line"><span class="built_in">print</span>(torch.version.cuda)</span><br></pre></td></tr></table></figure>

<p>实际上我在<code>import torch</code>时报错:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; import  torch</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span><br><span class="line">  File &quot;/home/varas/shijy/install_torch/pytorch/torch/__init__.py&quot;, line 214, in &lt;module&gt;</span><br><span class="line">    raise ImportError(textwrap.dedent(&#x27;&#x27;&#x27;</span><br><span class="line">ImportError: Failed to load PyTorch C extensions:</span><br><span class="line">    It appears that PyTorch has loaded the `torch/_C` folder</span><br><span class="line">    of the PyTorch repository rather than the C extensions which</span><br><span class="line">    are expected in the `torch._C` namespace. This can occur when</span><br><span class="line">    using the `install` workflow. e.g.</span><br><span class="line">        $ python setup.py install &amp;&amp; python -c &quot;import torch&quot;</span><br><span class="line"></span><br><span class="line">    This error can generally be solved using the `develop` workflow</span><br><span class="line">        $ python setup.py develop &amp;&amp; python -c &quot;import torch&quot;  # This should succeed</span><br><span class="line">    or by running Python from a different directory.</span><br></pre></td></tr></table></figure>

<p>按照提示执行<code>python setup.py develop</code>就好了。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.jianshu.com/p/ba6beab8ad7f">安装NVIDIA显卡驱动和CUDA Toolkit</a></p>
<p><a href="https://medium.com/analytics-vidhya/install-cuda-11-2-cudnn-8-1-0-and-python-3-9-on-rtx3090-for-deep-learning-fcf96c95f7a1">Install CUDA 11.2, cuDNN 8.1.0, PyTorch v1.8.0 (or v1.9.0), and python 3.9 on RTX3090 for deep learning</a></p>
]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title>用ssh反向代理完成内网穿透</title>
    <url>/2021/05/13/%E9%85%8D%E7%BD%AE/%E7%94%A8ssh%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%AE%8C%E6%88%90%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/</url>
    <content><![CDATA[<h2 id="内网穿透和反向代理"><a href="#内网穿透和反向代理" class="headerlink" title="内网穿透和反向代理"></a>内网穿透和反向代理</h2><p>想要从外网访问内网的服务器时，需要做内网穿透。反向代理是一种进行内网穿透的方法。</p>
<p>反向代理要求有一台公网的服务器来做代理，通俗地讲就是跳板。记内网服务器为T，公网服务器为O。T向O发起ssh反向代理请求，而后T和O就会建立ssh链接，O可以通过自身的反向代理端口访问T的ssh端口，然后O再把来自用户的ssh请求转发到反向代理端口，就可以让用户ssh链接到T了。</p>
<p>简单来说，由于内网是外网访问不到的，就在内网中主动向外网的服务器建立一个稳定的链接，然后外网的其他用户就可以通过这个外网的服务器访问内网了。</p>
<h2 id="ssh反向代理和端口转发配置"><a href="#ssh反向代理和端口转发配置" class="headerlink" title="ssh反向代理和端口转发配置"></a>ssh反向代理和端口转发配置</h2><h3 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h3><p>直接进行配置，在内网服务器上，向公网服务器发起反向代理请求:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh -fCNR 7280:localhost:22 root@remot_ip</span><br></pre></td></tr></table></figure>

<p>R选项：通过绑定远程主机上的地址和端口(port)，将该端口上收到的数据转发到host+hostport指定的端口上。</p>
<p>这条命令让远程服务器把7280端口的ssh链接转发到本地22端口。</p>
<p>ssh链接有时候会断，为了保证链接稳定，需要使用<code>autossh</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install autossh</span><br><span class="line">autossh -M 7281 ssh -fCNR 7280:localhost:22 root@remot_ip</span><br></pre></td></tr></table></figure>

<p>后一句命令指定了在远程主机上使用7281端口来监控、维持后面的ssh链接。</p>
<p>这时可以通过netstat命令来查看链接是否正常:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">netstat -tnlp</span><br></pre></td></tr></table></figure>

<p>如果7280和7281端口在监听状态，就没有问题。</p>
<p>也可以在公网服务器上尝试链接内网服务器来确认这一步正确:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh username@localhost -p 7280</span><br></pre></td></tr></table></figure>

<h3 id="端口转发"><a href="#端口转发" class="headerlink" title="端口转发"></a>端口转发</h3><p>用户不能直接通过公网服务器的7280端口去链接内网的服务器，需要另外指定一个端口，公网服务器将该端口的ssh链接转发到7280端口即可让用户链接到内网服务器，所以在公网服务器可以执行如下命令来做端口转发:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh -fCNL *:1234:localhost:7280 localhost</span><br></pre></td></tr></table></figure>

<p>表示将本地1234端口的ssh链接转发到7280端口。</p>
<h3 id="进行远程连接"><a href="#进行远程连接" class="headerlink" title="进行远程连接"></a>进行远程连接</h3><p>最后，用户可以直接ssh公网服务器的1234端口，从而连接到内网服务器:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh username@remote_ip -p 1234</span><br></pre></td></tr></table></figure>

<h2 id="开机自启"><a href="#开机自启" class="headerlink" title="开机自启"></a>开机自启</h2><p>2021.5.17 更新 注意注意:可能因为开机时没有网络，所以<code>autossh</code>脚本会运行失败，<strong>会导致启动失败</strong>，整个系统就启动不了。我在自己的机子上发现启动失败才发现。这也有可能是最近服务器重启的时候老是失败的原因…需要用启动盘去挂载<code>/</code>然后把启动脚本删了。所以还是<strong>别搞启动脚本</strong>了。</p>
<p>挂载<code>/</code>:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo mount /dev/xxx ~/r</span><br></pre></td></tr></table></figure>

<p>要搞启动脚本的话估计用frp做内网穿透是一个更好的办法，现在懒得改了(正常情况下服务器不会重启，暂时没这个需求了)。</p>
<p>以下是开机自启脚本配置方法原文，服务器上慎重使用：</p>
<p>反向代理命令开机自启，不然内网服务器一重启就连不上了。</p>
<p>把<code>autossh</code>命令写进一个脚本<code>autossh.sh</code>，然后放入<code>/etc/profile.d</code>文件夹下，给予执行权限。注意需要用root用户创建这个脚本，否则启动时可能没有足够的执行权限:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /etc/profile.d</span><br><span class="line">sudo su</span><br><span class="line">vim autossh.sh</span><br><span class="line"># 添加autossh命令</span><br><span class="line">sudo chmod +x autossh.sh</span><br></pre></td></tr></table></figure>

<p>按理说这样配置之后开机自启应该没问题了，但是我重启之后这条命令虽然被执行了，但是没有效果，必须kill掉这条命令然后手动重新执行才可以，找不到原因。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.jianshu.com/p/dafbbbe4c43b">使用SSH反向代理和端口转发</a></p>
<p><a href="https://blog.csdn.net/weixin_40429823/article/details/99006940">Linux以root权限开机自动运行脚本</a></p>
]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Attacking the Qualcomm Adreno GPU:CVE-2020-11179笔记</title>
    <url>/2021/07/08/GPU/Attacking-the-Qualcomm-Adreno-GPU-CVE-2020-11179%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>原文地址: <a href="https://googleprojectzero.blogspot.com/2020/09/attacking-qualcomm-adreno-gpu.html">Google Project Zero博客</a></p>
<h1 id="Attacking-the-Qualcomm-Adreno-GPU"><a href="#Attacking-the-Qualcomm-Adreno-GPU" class="headerlink" title="Attacking the Qualcomm Adreno GPU"></a>Attacking the Qualcomm Adreno GPU</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>这个工作基于CVE-2019-10567之上，作者注意到该漏洞修补不完整，于是和高通安全团队以及GPU工程师合作解决了这个漏洞的根本成因。补丁已经发送给OEM供应商进行集成。</p>
<h2 id="Android-攻击面"><a href="#Android-攻击面" class="headerlink" title="Android 攻击面"></a>Android 攻击面</h2><p>Android应用程序沙盒是SELinux、seccomp BPF过滤器和基于每个应用程序UID的独立访问控制的组合机制，在不断发展之中。沙盒用于限制应用程序可以访问的资源，并减少攻击面。攻击者使用许多众所周知的途径来逃离沙盒，例如：攻击其他应用程序、攻击系统服务或攻击Linux内核。</p>
<p>从高层看来，Android有很多不同类型的攻击面，重要的几个如下：</p>
<ul>
<li>普遍(Ubiquitous)攻击面<ul>
<li>影响所有设备。</li>
<li>如脏牛。</li>
</ul>
</li>
<li>芯片组攻击面<ul>
<li>影响大部分android设备，取决于各种OEM供应商使用的硬件类型。</li>
<li>如Snapdragon SoC性能计数器漏洞、Broadcom WiFi固件堆栈溢出。</li>
</ul>
</li>
<li>供应链攻击面<ul>
<li>影响特定Android OEM供应商的大多数或所有设备的问题</li>
<li>如Samsung内核驱动程序漏洞。</li>
</ul>
</li>
<li>设备攻击面<ul>
<li>影响Android原始设备制造商的特定设备型号的问题</li>
<li>Pixel 4 人脸解锁“Attention Aware”漏洞</li>
</ul>
</li>
</ul>
<p>对于Sandbox Escape而言，GPU是一个芯片组层面的有趣攻击面，因为很多Android应用会使用GPU加速计算，沙箱对底层GPU硬件有完全访问权限，Android设备中只有ARM Mali和Qualcomm Adreno两种类型的GPU设备。如果在这两种硬件设备中找到一个沙箱逃逸漏洞，则可以影响大部分设备。另外，由于GPU的复杂性和大量闭源组件(如微码和固件)，发现漏洞的可能性很大。</p>
<h2 id="CVE-2019-10567的补丁"><a href="#CVE-2019-10567的补丁" class="headerlink" title="CVE-2019-10567的补丁"></a>CVE-2019-10567的补丁</h2><p>注意到Qualcomm Adreno内核驱动代码的一个用于修补CVE-2019-10567的commit:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">From 0ceb2be799b30d2aea41c09f3acb0a8945dd8711 Mon Sep 17 00:00:00 2001</span><br><span class="line">From: Jordan Crouse &lt;jcrouse@codeaurora.org&gt;</span><br><span class="line">Date: Wed, 11 Sep 2019 08:32:15 -0600</span><br><span class="line">Subject: [PATCH] msm: kgsl: Make the &quot;scratch&quot; global buffer use a random GPU address</span><br><span class="line"></span><br><span class="line">Select a random global GPU address for the &quot;scratch&quot; buffer that is used by the ringbuffer for various tasks.</span><br></pre></td></tr></table></figure>

<p>为什么GPU侧需要ASLR？进而查看CVE-2019-10567的另一个commit:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">From 8051429d4eca902df863a7ebb3c04cbec06b84b3 Mon Sep 17 00:00:00 2001</span><br><span class="line">From: Jordan Crouse &lt;jcrouse@codeaurora.org&gt;</span><br><span class="line">Date: Mon, 9 Sep 2019 10:41:36 -0600</span><br><span class="line">Subject: [PATCH] msm: kgsl: Execute user profiling commands in an IB</span><br><span class="line"></span><br><span class="line">Execute user profiling in an indirect buffer. This ensures that addresses and values specified directly from the user don&#x27;t end up in the ringbuffer.</span><br></pre></td></tr></table></figure>

<p>为什么不能让用户提供的内容出现在ringbuffer里？这个补丁真的能防止这个吗？如果恢复了scratch buffer的base address会发生什么？</p>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="Adreno-Introduction"><a href="#Adreno-Introduction" class="headerlink" title="Adreno Introduction"></a>Adreno Introduction</h3><p>GPU硬件通常由OpenGL ES和Valkan等库抽象出来，这些库实现了标准API，以用于可编程通用GPU加速操作，在底层，这是通过与运行在内核空间的GPU设备驱动程序交互来实现的。</p>
<p><img src="image2.png" alt="GPU内核驱动"></p>
<p>在Qualcomm Adreno中，<code>/dev/kgsl-3d0</code>设备文件被用来实现高级GPU功能，它可以在不受信任的应用程序中直接访问。</p>
<ul>
<li><p>设备文件权限设置在<a href="https://android.googlesource.com/platform/system/core/+/master/init/README.ueventd.md">ueventd</a>中:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sargo:/ # cat /system/vendor/ueventd.rc | grep kgsl-3d0</span><br><span class="line">/dev/kgsl-3d0             0666   system     system</span><br></pre></td></tr></table></figure></li>
<li><p>设备文件的SELinux标签为<code>gpu_device</code>，且<code>untrusted_app</code>的SELinux上下文中有一条针对该标签的特定允许规则:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sargo:/ # ls -Zal /dev/kgsl-3d0</span><br><span class="line">crw-rw-rw- 1 system system u:object_r:gpu_device:s0 239, 0 2020-07-21 </span><br><span class="line">15:48 /dev/kgsl-3d0</span><br><span class="line"></span><br><span class="line">hawkes@glaptop:~$ adb pull /sys/fs/selinux/policy</span><br><span class="line">/sys/fs/selinux/policy: 1 file pulled, 0 skipped. 16.1 MB/s ...</span><br><span class="line">hawkes@glaptop:~$ sesearch -A -s untrusted_app policy | grep gpu_device</span><br><span class="line">allow untrusted_app gpu_device:chr_file &#123; append getattr ioctl lock map open read write &#125;;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>因此<code>untrusted_app</code>可以打开设备文件。Adreno “KGSL(Kernel Graphics Support Layer)”内核驱动主要通过<code>ioctl</code>(如分配共享内存、创建GPU上下文、提交GPU命令等)和<code>mmap</code>(如映射共享内存到用户态应用程序)来调用。</p>
<h3 id="GPU-Shared-Mappings"><a href="#GPU-Shared-Mappings" class="headerlink" title="GPU Shared Mappings"></a>GPU Shared Mappings</h3><p>通常情况下，应用程序通过shared mappings将顶点、片元和着色器加载到GPU上和接收计算结果。因此某些物理页在用户态应用程序和GPU硬件之间是共享的。</p>
<p>用户通过<code>IOCTL_KGSL_GPUMEM_ALLOC</code>的<code>ioctl</code>调用向KGSL内核驱动程序请求分配，内核驱动分配一个物理内存区域后将其映射至GPU地址空间(某个特定context中)，最后，应用使用<code>allocation ioctl</code>返回的标识符将共享内存映射至用户地址空间。</p>
<p>此时物理页有两种不同视图：</p>
<ul>
<li>用户态应用程序：使用虚拟地址访问映射到其用户态地址空间的内存。由CPU的MMU进行虚拟地址-物理地址转换。</li>
<li>GPU硬件本身: 使用由KGSL内核驱动选择的GPU虚拟地址，内核驱动通过一个GPU专用页表结构配置设备的IOMMU(ARM中叫SMMMU)。GPU读写共享内存时，IOMMU将GPU虚拟地址转换为物理页，类似于CPU上执行的地址转换，但使用完全不同的地址空间(程序中的指针和GPU中的指针值不同)。</li>
</ul>
<p><img src="image1.png" alt="两种地址转换"></p>
<p>每个用户态进程都有自己的GPU context，当某应用在GPU运行时，GPU只能访问它与该进程共享的内存映射，一个程序不能要求GPU从另一个程序读取共享映射。具体实现中，在GPU上下文切换时，切换加载到IOMMU中的页表。每当GPU被调度运行来自不同进程的命令时，就会发生上下文切换。</p>
<p><strong>全局共享映射</strong>会被所有GPU上下文共享，出现在每一组页表中，用于GPU和KGSL内核驱动程序之间的各种系统和调试功能。它们不会直接映射到用户态程序中，它们会映射到GPU和内核地址空间中。</p>
<p>在有root权限的安卓设备上，可以通过<code>cat /sys/kernel/debug/kgsl/globals</code>查看GPU全局内存映射，从而看到scratch buffer(临时缓冲区)。通过多次重启设备，可以发现scratch buffer开启了随机化，其他全局内存映射都在[0xFC000000, 0xFD400000]之间的固定位置。其中的原因是<code>CVE-2019-10567</code>的补丁只为scratch buffer分配提供了<code>KGSL_MEMDESC_RANDOM </code> flag。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0x00000000fc0df000-0x00000000fc0dffff             4096 scratch</span><br><span class="line">...</span><br><span class="line">0x00000000fcfc0000-0x00000000fcfc0fff             4096 scratch</span><br><span class="line">...</span><br><span class="line">0x00000000fc9ff000-0x00000000fc9fffff             4096 scratch</span><br><span class="line">...</span><br><span class="line">0x00000000fcb4d000-0x00000000fcb4dfff             4096 scratch</span><br></pre></td></tr></table></figure>

<p>总之，临时缓冲区是一个正确开启了随机化的全局映射区域。</p>
<h3 id="The-Scratch-Buffer"><a href="#The-Scratch-Buffer" class="headerlink" title="The Scratch Buffer"></a>The Scratch Buffer</h3><p>驱动程序源码中，scratch buffer在驱动的probe routines(探测例程)中被分配，因此scratch buffer仅在设备初始化时初始化:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int adreno_ringbuffer_probe(struct adreno_device *adreno_dev, bool nopreempt)&#123;</span><br><span class="line">    ...</span><br><span class="line">    status = kgsl_allocate_global(device, &amp;device-&gt;scratch,</span><br><span class="line">                                PAGE_SIZE, 0, KGSL_MEMDESC_RANDOM, &quot;scratch&quot;);</span><br><span class="line"> /* SCRATCH MEMORY: The scratch memory is one page worth of data that</span><br><span class="line"> *  is mapped into the GPU. This allows for some &#x27;shared&#x27; data between</span><br><span class="line"> *  the GPU and CPU. For example, it will be used by the GPU to write</span><br><span class="line"> *  each updated RPTR for each RB.</span><br></pre></td></tr></table></figure>

<p>综合<code>device-&gt;scratch</code>的用法看来，它主要的作用如下:</p>
<ul>
<li>高优先级的GPU command中断低优先级的GPU command时，用来存放preemption restore buffer(抢占恢复缓冲区)的GPU地址。</li>
<li>需要计算ringbuffer(RB)的空闲空间时，在scratch buffer中被读取RB的读取指针(RPTR)。</li>
</ul>
<p><code>CVE-2019-10567</code>的补丁修改了对scratch buffer和RB的处理代码，因此应该关注上述第二种用例。</p>
<p>当GPU正在向共享映射中写入RPTR，且内核驱动程序正在从scratch buffer中读取RPTR值并将其用于分配大小的计算时，如果我们让GPU写入一个无效或错误的RPTR值会发生什么？</p>
<h3 id="Ringbuffer-Basics"><a href="#Ringbuffer-Basics" class="headerlink" title="Ringbuffer Basics"></a>Ringbuffer Basics</h3><p>ringbuffer的作用: 用户态应用程序提交GPU命令(<code>IOCTL_KGSL_GPU_COMMAND</code>)，驱动代码通过ringbuffer将命令发给GPU，内核驱动程序把命令写入ringbuffer，GPU从ringbuffer读取命令。</p>
<p>ringbuffer机制和典型<a href="https://en.wikipedia.org/wiki/Circular_buffer">circular buffers</a>类似。在低层看来，ringbuffer是一个固定大小为32768bytes的全局共享映射，ringbuffer用两个指针索引，WPTR记录CPU正在写的位置，RPTR记录GPU正在读取的位置。为了在ringbuffer分配空间，CPU需要计算WPTR和RPTR之间的空闲空间。<code>adreno_ringbuffer_allocspace</code>中代码如下:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">unsigned</span> <span class="keyword">int</span> *<span class="title">adreno_ringbuffer_allocspace</span><span class="params">(struct adreno_ringbuffer *rb,</span></span></span><br><span class="line"><span class="params"><span class="function">                <span class="keyword">unsigned</span> <span class="keyword">int</span> dwords)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">adreno_device</span> *<span class="title">adreno_dev</span> =</span> <span class="built_in">ADRENO_RB_DEVICE</span>(rb);</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> rptr = <span class="built_in">adreno_get_rptr</span>(rb); [<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> ret;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> (rptr &lt;= rb-&gt;_wptr) &#123; [<span class="number">2</span>]</span><br><span class="line">                <span class="keyword">unsigned</span> <span class="keyword">int</span> *cmds;</span><br><span class="line">                <span class="keyword">if</span> (rb-&gt;_wptr + dwords &lt;= (KGSL_RB_DWORDS - <span class="number">2</span>)) &#123;</span><br><span class="line">                        ret = rb-&gt;_wptr;</span><br><span class="line">                        rb-&gt;_wptr = (rb-&gt;_wptr + dwords) % KGSL_RB_DWORDS;</span><br><span class="line">                        <span class="keyword">return</span> <span class="built_in">RB_HOSTPTR</span>(rb, ret);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">/* </span></span><br><span class="line"><span class="comment">                 * There isn&#x27;t enough space toward the end of ringbuffer. So</span></span><br><span class="line"><span class="comment">                 * look for space from the beginning of ringbuffer upto the</span></span><br><span class="line"><span class="comment">                 * read pointer.</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (dwords &lt; rptr) &#123;</span><br><span class="line">                        cmds = <span class="built_in">RB_HOSTPTR</span>(rb, rb-&gt;_wptr);</span><br><span class="line">                        *cmds = <span class="built_in">cp_packet</span>(adreno_dev, CP_NOP,</span><br><span class="line">                                KGSL_RB_DWORDS - rb-&gt;_wptr - <span class="number">1</span>);</span><br><span class="line">                        rb-&gt;_wptr = dwords;</span><br><span class="line">                        <span class="keyword">return</span> <span class="built_in">RB_HOSTPTR</span>(rb, <span class="number">0</span>);</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (rb-&gt;_wptr + dwords &lt; rptr) &#123; [<span class="number">3</span>]</span><br><span class="line">                ret = rb-&gt;_wptr;</span><br><span class="line">                rb-&gt;_wptr = (rb-&gt;_wptr + dwords) % KGSL_RB_DWORDS;</span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">RB_HOSTPTR</span>(rb, ret); [<span class="number">4</span>]</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">ERR_PTR</span>(-ENOSPC);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">unsigned</span> <span class="keyword">int</span> <span class="title">adreno_get_rptr</span><span class="params">(struct adreno_ringbuffer *rb)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">adreno_device</span> *<span class="title">adreno_dev</span> =</span> <span class="built_in">ADRENO_RB_DEVICE</span>(rb);</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> rptr = <span class="number">0</span>;</span><br><span class="line">...</span><br><span class="line">                <span class="class"><span class="keyword">struct</span> <span class="title">kgsl_device</span> *<span class="title">device</span> =</span> <span class="built_in">KGSL_DEVICE</span>(adreno_dev);</span><br><span class="line">                <span class="built_in">kgsl_sharedmem_readl</span>(&amp;device-&gt;scratch, &amp;rptr,              <span class="built_in">SCRATCH_RPTR_OFFSET</span>(rb-&gt;id)); [<span class="number">5</span>]</span><br><span class="line">...</span><br><span class="line">        <span class="keyword">return</span> rptr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>RPTR被攻击者控制时，攻击者可以用刚写入的GPU命令覆盖还没有处理的GPU命令。因此，控制scratch buffer中的rptr值可以CPU和GPU之间对ringbuffer的同步收到破坏。</p>
<h2 id="Attacking-the-Scratch-RPTR"><a href="#Attacking-the-Scratch-RPTR" class="headerlink" title="Attacking the Scratch RPTR"></a>Attacking the Scratch RPTR</h2><p>全局共享映射在CPU侧没有映射到用户态，因此不能直接在恶意应用写入scratch buffer中的RPTR，但由于scratch buffer映射到了每一个GPU context，包括攻击者进程的GPU context，因此可以从GPU侧写入恶意RPTR到scratch buffer。</p>
<p>这个过程需要进行如下两步:</p>
<ul>
<li>验证该映射可以由用户可用的GPU命令写入。</li>
<li>恢复scratch mapping的GPU基址，它开启了ASLR。</li>
</ul>
<h3 id="验证scratch-bufer可写"><a href="#验证scratch-bufer可写" class="headerlink" title="验证scratch bufer可写"></a>验证scratch bufer可写</h3><h4 id="实验验证"><a href="#实验验证" class="headerlink" title="实验验证"></a>实验验证</h4><p>并不是所有的全局共享映射都能被用户可用的GPU命令写入，但是可以证实scratch buffer是可写的。通过前述<code>sysfs</code>调试方法来找到scratch mapping的随机基址，然后用如下GPU命令序列来写入scratch mapping:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* write a value to the scratch buffer at offset 256 */</span></span><br><span class="line">    *cmds++ = <span class="built_in">cp_type7_packet</span>(CP_MEM_WRITE, <span class="number">3</span>);</span><br><span class="line">    cmds += <span class="built_in">cp_gpuaddr</span>(cmds, SCRATCH_BASE+<span class="number">256</span>);</span><br><span class="line">    *cmds++ = <span class="number">0x41414141</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* ensure that the write has taken effect */</span></span><br><span class="line">    *cmds++ = <span class="built_in">cp_type7_packet</span>(CP_WAIT_REG_MEM, <span class="number">6</span>);</span><br><span class="line">    *cmds++ = <span class="number">0x13</span>;</span><br><span class="line">    cmds += <span class="built_in">cp_gpuaddr</span>(cmds, SCRATCH_BASE+<span class="number">256</span>);</span><br><span class="line">    *cmds++ = <span class="number">0x41414141</span>;</span><br><span class="line">    *cmds++ = <span class="number">0xffffffff</span>;</span><br><span class="line">    *cmds++ = <span class="number">0x1</span>;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">/* write 1 to userland shared memory to signal success */</span></span><br><span class="line">    *cmds++ = <span class="built_in">cp_type7_packet</span>(CP_MEM_WRITE, <span class="number">3</span>);</span><br><span class="line">    cmds += <span class="built_in">cp_gpuaddr</span>(cmds, shared_mem_gpuaddr);</span><br><span class="line">    *cmds++ = <span class="number">0x1</span>;</span><br></pre></td></tr></table></figure>

<p>每个<code>CP_*</code>操作都在用户态构造、在GPU硬件运行。应用中一般直接使用OpenGL库函数和着色器，然后再被翻译为这些供应商支持库中的原生操作，但攻击者也可以直接通过设置GPU共享内存、调用<code>IOCTL_KGSL_GPU_COMMAND</code>来构造命令序列。但是这些操作没有在文档中记录，只能从驱动代码和手动测试中推断，部分操作为:</p>
<ul>
<li><code>CP_MEM_WRITE</code>: 向GPU地址写入一个常量。</li>
<li><code>CP_WAIT_REG_MEM</code>: 在一个GPU地址中是某个常量值之前暂停执行。</li>
<li><code>CP_MEM_TO_MEM</code>: 在GPU地址间拷贝内存。</li>
</ul>
<p>因此上述代码可以通过检查<code>CP_WAIT_REG_MEM</code>返回值确定GPU是否向scratch buffer写入成功。</p>
<h4 id="通过内核驱动代码验证"><a href="#通过内核驱动代码验证" class="headerlink" title="通过内核驱动代码验证"></a>通过内核驱动代码验证</h4><p>还可以通过验证内核驱动代码中对全局共享映射的页表的设置来确定scratch buffer是否可写。事实上，由于调用<code>kgsl_allocate_global</code>时没有设置<code>KGSL_MEMFLAGS_GPUREADONLY</code>或<code>KGSL_MEMDESC_PRIVILEGED</code>两个flag，scratch buffer是用户GPU命令可写的。</p>
<h3 id="获取scratch-buffer基址"><a href="#获取scratch-buffer基址" class="headerlink" title="获取scratch buffer基址"></a>获取scratch buffer基址</h3><h4 id="暴力破解"><a href="#暴力破解" class="headerlink" title="暴力破解"></a>暴力破解</h4><p>由于全局映射的地址范围是固定的，且仅scratch buffer基址是随机化的，在排除其它静态全局共享映射位置之后，仅有2721个可能存放scratch page的位置，在一个中端智能机中平均需要花七分半来恢复scratch buffer地址，且时间上还有进一步优化空间。</p>
<h4 id="另一种方法"><a href="#另一种方法" class="headerlink" title="另一种方法"></a>另一种方法</h4><p>scratch buffer还用于抢占，用来存放preemption restore buffer的基址。在抢占对GPU做准备时，内核驱动会调用<code>a6xx_preemption_pre_ibsubmit</code>函数，该函数会在ringbuffer中插入一些操作，它还会把scratch buffer指针放入ringbuffer中，作为<code>CP_MEM_WRITE</code>操作的指针。由于ringbuffer是一个用户可读的全局映射，因此有可能在ringbuffer合适的偏移位置提取出scratch buffer指针。</p>
<h2 id="Overwriting-the-Ringbuffer"><a href="#Overwriting-the-Ringbuffer" class="headerlink" title="Overwriting the Ringbuffer"></a>Overwriting the Ringbuffer</h2><p>现在可以控制scratch RPTR的值了，接下来考虑如何重写ringbuffer，能够带来什么效果。</p>
<p>实际上有四个用于不同GPU优先级的ringbuffer，测试中选择了Android设备中使用最少的一个，以避免噪声(ringbuffer 0，根本没有被使用)。</p>
<p>ringbuffer全局映射有<code>KGSL_MEMFLAGS_GPUREADONLY</code>标志，因此不能直接修改ringbuffer内容，需要通过scratch RPTR原语来达到这个目的。</p>
<p>ringbuffer用于将命令从CPU发送到GPU，但是实践中，用户提供的GPU命令从不直接放在ringbuffer中，因为:</p>
<ul>
<li>空间限制：ringbuffer空间有限，GPU命令可能很大。</li>
<li>进程隔离：所有GPU上下文都可以读取ringbuffer，希望确保一个进程只能读取该进程的命令。</li>
</ul>
<p>实际上，系统级GPU命令是直接放在ringbuffer中运行的；用户级命令通过一个“间接分支“执行，用户级命令放在GPU共享内存中，它通过由<code>adreno_ringbuffer_submitcmd</code>插入ringbuffer的<code>CP_INDIRECT_BUFFER_PFE </code>操作实现，该操作有两个参数，用户GPU命令的GPU地址和大小。用户级命令执行完成后回到ringbuffer中继续执行下一条ringbuffer中的命令。</p>
<p>除了”间接分支“操作以外，ringbuffer还有很多其他GPU命令设置和收尾操作，类似函数的序言和结语。包括抢占设置、GPU上下文切换、性能监控hook、勘误表修正、标识符、保护模式操作等。本文选定保护模式作为攻击目标。</p>
<h2 id="Protected-Mode"><a href="#Protected-Mode" class="headerlink" title="Protected Mode"></a>Protected Mode</h2><p>保护模式：GPU运行用户GPU命令时，会启动保护模式，限制对一些全局共享映射和寄存器的访问。在驱动代码中，只有很少一部分操作在禁用保护模式下运行，如抢占、勘误表修正、性能监控和GPU上下文切换相关操作。</p>
<p>那么，在上下文切换的时候，如果让GPU切换到攻击者控制的页表，攻击者就可以对任意物理地址进行读写，包括内核内存。</p>
<p>查看内核驱动代码发现，在切换上下文时，ringbuffer中有一个<code>CP_SMMU_TABLE_UPDATE</code>操作，使得GPU切换页表，而非切换IOMMU页表，这可能是基于性能考虑，避免使用内核中断、等待IOMMU被配置好。</p>
<p>进一步查看发现，GPU将IOMMU的<code>TTBR0</code>寄存器映射到保护模式GPU寄存器中，该寄存器用于存放IOMMU中GPU地址转换为物理内存地址的页表基址。这意味着<code>TTBR0</code>指向恶意页表后，就可以让任意GPU地址转换为任意物理地址。</p>
<h5 id="CVE-2019-10567"><a href="#CVE-2019-10567" class="headerlink" title="CVE-2019-10567"></a>CVE-2019-10567</h5><p>在<code>CVE-2019-10567</code>补丁中，有两项措施:</p>
<ul>
<li>随机化scratch buffer位置</li>
<li>确保用户指定的地址和值不会出现在ring buffer中</li>
</ul>
<p>在<a href="https://github.com/secmob/TiYunZong-An-Exploit-Chain-to-Remotely-Root-Modern-Android-Devices/blob/master/us-20-Gong-TiYunZong-An-Exploit-Chain-to-Remotely-Root-Modern-Android-Devices-wp.pdf">whitepaper</a>中，Guang Gong的攻击通过:</p>
<ul>
<li>将恶意操作作为性能探测命令的参数插入ringbuffer。</li>
<li>破坏scratch buffer(当时是静态地址)中的RPTR指针，使其指向恶意操作。</li>
<li>恶意操作会关闭保护模式，然后分支到攻击者控制的GPU命令，然后覆盖<code>TTBR0</code>寄存器，获取任意物理地址读写权限。</li>
</ul>
<h2 id="Recovering-the-Attack"><a href="#Recovering-the-Attack" class="headerlink" title="Recovering the Attack"></a>Recovering the Attack</h2><p>之前已经绕过了scratch buffer的的地址随机化补丁，接下来需要绕过第二个部分，它通过分析子系统(profiling subsystem)防止攻击者控制的命令被写入ringbuffer，最简单的是使用其他方法插入攻击者控制的命令(如使用用户提供的GPU地址作为命令操作码)，但作者采用了另一种竞争方法。</p>
<h3 id="攻击思路"><a href="#攻击思路" class="headerlink" title="攻击思路"></a>攻击思路</h3><p>保护模式的操作模式是:</p>
<ul>
<li>关闭保护模式</li>
<li>执行特权操作</li>
<li>重新启用保护模式</li>
</ul>
<p>这里选定上下文切换操作为目标。</p>
<p>主要攻击思路是，在GPU执行了关闭保护模式操作之后、执行上下文切换操作和开启保护模式之前，通过修改RPTR指针，让上下文切换操作被覆盖为攻击者控制的间接分支操作，在间接分支中覆盖<code>TTBR0</code>寄存器，使其指向攻击者控制的的页表，从而获取任意地址读取权限。</p>
<p><img src="image3.png" alt="攻击概览"></p>
<p>为了竞争成功，需要将间接分支写入到ringbuffer中正确的偏移量，且需要计时，以确保写入时GPU刚好执行了禁用保护模式，且没有执行上下文切换。</p>
<h3 id="具体方法"><a href="#具体方法" class="headerlink" title="具体方法"></a>具体方法</h3><p>实践中，通过wait命令在GPU启用保护模式之前暂停GPU，在这段时间内找到GPU上下文切换操作的offset，即写入间接分支的位置，wait命令后，直接在ringbuffer中覆盖写入，覆盖写入的offset很稳定，可能因为有缓存行为或内部预取缓冲区。这个竞争有20%的成功率，失败了不会有负面效果，因此可以不断尝试。</p>
<p>成功后，在禁用保护模式的情况下，进入攻击者提供的分支，修改<code>TTBR0</code>寄存器，使其指向恶意页表的物理地址。由于使用的物理地址，所以在构造恶意页表的时候需要知道分配的恶意页表内存你的物理地址，已有的在某一已知物理地址写入数据的方法有两个:</p>
<ul>
<li>使用ION内存分配器</li>
<li>通过伙伴系统喷射内存</li>
</ul>
<p>通过第二种方法获得了成功。</p>
<p>最终通过恶意页表能够任意读写Android内核代码和数据结构，导致内核任意代码执行。</p>
<h2 id="Final-Attack"><a href="#Final-Attack" class="headerlink" title="Final Attack"></a>Final Attack</h2><p><a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2052">PoC源码</a>。</p>
<p>除了20%的成功率以外，还有两个不稳定因素:</p>
<ul>
<li>在不同版本的内核中，ringbuffer偏移可能不同。但是可以自动计算出来。</li>
<li>在已知物理地址分配内存的喷射技术很基本，仅用于演示，且所选的固定页可能正在使用中。可以选择使用ION方法或其他方法。</li>
</ul>
<h1 id="PoC源码解析"><a href="#PoC源码解析" class="headerlink" title="PoC源码解析"></a>PoC源码解析</h1><p>PoC源码一共有四个文件:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">adrenaline.cpp</span><br><span class="line">adrenaline.h</span><br><span class="line">MainActivity.java</span><br><span class="line">AdrenalineService.java</span><br></pre></td></tr></table></figure>

<p>java部分在应用中注册了<code>AdrenalineService</code>实例，该service调用c++后台的<code>stringFromJNI</code>函数，获取字符串返回值并打印在屏幕上。因此c++中的<code>stringFromJNI</code>函数是PoC的入口。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="function">JNIEXPORT jstring JNICALL</span></span><br><span class="line"><span class="function"><span class="title">Java_com_projectzero_adrenaline_AdrenalineService_stringFromJNI</span><span class="params">(JNIEnv* env, jobject)</span> </span>&#123;</span><br><span class="line">    std::string ret;</span><br><span class="line">    <span class="keyword">uint32_t</span> rptr_base = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    rptr_base = <span class="built_in">adrenaline_rptr</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (rptr_base == <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> env-&gt;<span class="built_in">NewStringUTF</span>(<span class="string">&quot;adrenaline_rptr failed&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (rptr_base &lt; <span class="number">0xFC000000</span> || rptr_base &gt;= <span class="number">0xFD400000</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> env-&gt;<span class="built_in">NewStringUTF</span>(<span class="string">&quot;adrenaline_rptr out of global mapping range&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ret = <span class="built_in">adrenaline</span>(rptr_base);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> env-&gt;<span class="built_in">NewStringUTF</span>(ret.<span class="built_in">c_str</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="adrenaline-rptr"><a href="#adrenaline-rptr" class="headerlink" title="adrenaline_rptr()"></a>adrenaline_rptr()</h2><p><code>adrenaline_rptr</code>函数的作用是获取scratch buffer基址，为了保证主线程状态的干净，开了一个子线程来获取，获取后通过pipe传输给主线程。子线程中在ring0创建了一个context，该context执行<code>CP_MEM_TO_MEM</code>命令，将GPU地址<code>0xfc04b318</code>处的数据直接拷贝到data_buf，取高位作为结果写入pipe给父线程。</p>
<p>解释如下:</p>
<ul>
<li><p><code>0xfc04b318</code>是ringbuffer0中的内容，不能保证在所有版本的内核中有效，ringbuffer内容会随着版本改变而改变。</p>
</li>
<li><p>具体而言，该地址存储了<code>a6xx_preemption_pre_ibsubmit</code>中<code>CP_MEM_WRITE</code>的目标地址参数，该目标地址是<code>scratch buffer</code>中的一个位置。</p>
<blockquote>
<p> scratch buffer中存放preemption restore buffer(抢占恢复缓冲区)指针的GPU地址。</p>
</blockquote>
</li>
</ul>
<h2 id="adrenaline-rptr-base"><a href="#adrenaline-rptr-base" class="headerlink" title="adrenaline(rptr_base)"></a>adrenaline(rptr_base)</h2><p>该函数是主要攻击函数，同样fork了两个线程，子线程用来创建上下文切换命令，用于竞争。父线程是主要攻击逻辑。</p>
<h3 id="子线程"><a href="#子线程" class="headerlink" title="子线程"></a>子线程</h3><p>子线程流程比较简单:</p>
<ul>
<li>在ring0中创建一个context</li>
<li>读取pipe，等待父线程的同步信号。</li>
<li>向创建的context中写入一个GPU命令(GPU执行到该命令后会发生上下文切换)</li>
<li>写入pipe，通知父线程上下文切换命令已经写入到ringbuffer</li>
</ul>
<h3 id="父线程"><a href="#父线程" class="headerlink" title="父线程"></a>父线程</h3><h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><p>父线程一开始mmap了几段buf，每个buf大小都是一页，且映射到了gpu:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">| wait_cmd_buf | data_buf | nop_buf | payload_buf |</span><br></pre></td></tr></table></figure>

<p>而后在ring0中创建了一个context。</p>
<h5 id="构造虚假页表"><a href="#构造虚假页表" class="headerlink" title="构造虚假页表"></a>构造虚假页表</h5><p>虚假页表存放的目标物理地址是<code>0xfebeb000</code>，使用简单的喷射方法来尝试在该位置分配虚假页表。循环64次:</p>
<ul>
<li>分配4096页(16mb)内存，在每一页都写入一个虚假页表。</li>
<li>虚假页表中，将gpu地址<code>0x40403000</code>映射到了内核中的系统调用表位置<code>0x821D9000</code></li>
</ul>
<h4 id="主要逻辑"><a href="#主要逻辑" class="headerlink" title="主要逻辑"></a>主要逻辑</h4><p><img src="image3.png" alt="攻击概览"></p>
<h5 id="准备阶段"><a href="#准备阶段" class="headerlink" title="准备阶段"></a>准备阶段</h5><ul>
<li>向ringbuffer中填入868个nop命令，使得wait命令大致在中间的位置。(因为ringbuffer0基本没有其他应用使用，所以大概大小是ringbuffer0的一半)</li>
<li>写入wait_cmds命令，在其后放入36个nop(数量可能是基于缓存行或者预取buffer大小对齐的，所以比较稳定)，使得<ul>
<li>wait_cmds包含:<ul>
<li>wait1: 等待data_buf[0]值为<code>0x41414141</code>，那将标志着ringbuffer布局调整完成。</li>
<li>rptr: 写入scratch buffer rptr为<code>0x1ffc</code>，覆盖rptr。</li>
<li>wait_rptr: 等待scratch buffer rptr的值为<code>0x1ffc</code>，确保上一步写入成功。</li>
<li>wait2: 等待data_buf[1]值为<code>0x42424242</code>，那将标志ringbuffer攻击开始。</li>
</ul>
</li>
</ul>
</li>
<li>向pipe写入同步信号，使得子线程写入一个命令，触发GPU上下文切换，在ringbuffer中插入关闭保护模式的命令。</li>
<li>等待子线程的同步信号，表示上下文切换命令已经写入ringbuffer。</li>
<li>写入888个nop指令，使得wptr大约在ringbuffer的开头，接下来的GPU命令写到ringbuffer开头位置。</li>
<li>写入101个nop指令，用来保证竞争时的对齐，避免出错。</li>
</ul>
<h5 id="开始攻击"><a href="#开始攻击" class="headerlink" title="开始攻击"></a>开始攻击</h5><ul>
<li>向data_buf[0]写入<code>0x41414141</code>，使得wait_cmds中的rptr命令被执行。<ul>
<li>此时rptr指针被修改，之后的写入将可以覆盖之前的命令。</li>
<li>GPU卡在wait2处。</li>
</ul>
</li>
<li>写入payload，包括:<ul>
<li>0x374个nop命令，足以覆盖所有ringbuffer内容，包括wait_cmds,之前写的nops以及上下文切换命令。</li>
<li>payload 间接分支:<ul>
<li>一个nop</li>
<li>借用驱动中”stabler synchrominzation”代码，主要使用<code>CP_INDIRECT_BUFFER_PFE</code>命令插入间接分支。实际上指定的间接分支位置就在ringbuffer中。</li>
<li>一个指令，将恶意页表物理地址写入TTBR0寄存器。</li>
<li>页表改变后的驱动行为。</li>
<li>一些指令，在GPU映射中覆盖内核系统调用表，表示攻击成功。</li>
</ul>
</li>
<li>payload被dispatch后，所有命令都将被覆盖。</li>
</ul>
</li>
<li>向data_buf[0]写入<code>0x42424242</code>，使得wait2之后的命令被执行。</li>
</ul>
<p>之后，理想情况下，切换上下文命令时，刚关闭保护模式，payload被解析，导致所有GPU命令被覆盖，从而执行payload的间接分支。</p>
<p>实际上我对整个攻击中的ringbuffer布局还没有想清楚，可能对GPU命令机制还不够了解，需要深入看驱动代码。</p>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>GPU</tag>
        <tag>Android</tag>
        <tag>攻击</tag>
      </tags>
  </entry>
</search>
